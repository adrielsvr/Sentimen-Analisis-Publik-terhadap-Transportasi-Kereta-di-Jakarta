{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaTKP+BI18HpOdSkPjIbv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrielsvr/Sentimen-Analisis-Publik-terhadap-Transportasi-Kereta-di-Jakarta/blob/main/Preprocessing/Preprocessing_Transportasi_Kereta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPlMu5TJZrQ9",
        "outputId": "adfafd18-5a8d-4252-a46a-18eccb3af203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "# Instalasi library yang dibutuhkan\n",
        "!pip install nltk\n",
        "!pip install sastrawi\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from google.colab import drive\n",
        "import requests\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvfmX9UZuiB",
        "outputId": "2696c518-101a-4d82-bf96-4d1b5a2c18e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset twitter mengenai KRL, MRT dan LRT\n",
        "load_krl= pd.read_excel('/content/drive/MyDrive/Tugas Akhir/Dataset Twitter/Dataset/Data_KRL23.xlsx')\n",
        "load_mrt = pd.read_excel('/content/drive/MyDrive/Tugas Akhir/Dataset Twitter/Dataset/Data_MRT23.xlsx')\n",
        "load_lrt = pd.read_excel('/content/drive/MyDrive/Tugas Akhir/Dataset Twitter/Dataset/Data_LRT23.xlsx')\n",
        "\n",
        "data_krl = pd.DataFrame(load_krl['full_text'])\n",
        "data_mrt = pd.DataFrame(load_mrt['full_text'])\n",
        "data_lrt = pd.DataFrame(load_lrt['full_text'])\n",
        "\n",
        "print(data_lrt.head())\n",
        "print(data_mrt.head())\n",
        "print(data_krl.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lVHrmhgaCMA",
        "outputId": "e97a8fe9-5f94-4d17-bf2f-52157c300072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           full_text\n",
            "0  LRT Jabodebek siap mengatasi kemacetan. Yuk ce...\n",
            "1  Dewi Perssik Sebut Nikita Mirzani Jualan Apem ...\n",
            "2  Viral Rok Model Melorot, Rachel Vennya Tampil ...\n",
            "3  Kebangun abis mimpi naik LRT jakarta nyampe di...\n",
            "4  Saat @erickthohir mendampingi presiden Jokowi ...\n",
            "                                           full_text\n",
            "0  Ada Perubahan Jadwal Operasional MRT Jakarta S...\n",
            "1  @UGM_FESS 4. Lebih bagus lagi kalo bisa pelaja...\n",
            "2  https://t.co/qCPONlISDS Bali needs airport tra...\n",
            "3  @WatchmenID Terlalu fokus dengan perang, bom d...\n",
            "4  siapa disini yg cita-cita nya strolling arroun...\n",
            "                                           full_text\n",
            "0  @miaetsumi Hai, Kak. Untuk kartu KRL Commuter ...\n",
            "1  Keujanan di Bogor, menggigil selama di KRL, pa...\n",
            "2  @tanyarlfes Karena aku bkn orang jakarta, tiap...\n",
            "3  @adriansyahyasin Justru di hari lebaran itu KR...\n",
            "4  @JakartaAwayDay Udah gak ada ruang lagi ah di ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefenisikan fungsi untuk cleaning & case folding\n",
        "def clean_text(text):\n",
        "    # Menghapus mention\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)\n",
        "    # Menghapus karakter khusus\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    # Menghapus semua karakter non-word\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    # Menghapus tautan\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "    # Menghapus hashtag\n",
        "    text = re.sub(r\"#\\w+\", \"\", text)\n",
        "    # Menghapus emoji\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # Simbol & Tanda\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # Transportasi & Simbol Transportasi\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # Bendera\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # Simbol & Karakter Aksara CJK\n",
        "                               u\"\\U00002702-\\U000027B0\"  # Simbol, Tanda, & Karakter Aksara Dingbat\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    # Menghapus whitespace tambahan\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # Menghapus angka\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    # Menormalisasi huruf kecil\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Mengimplementasikan fungsi clean_text ke dataset\n",
        "data_krl['clean_text'] = data_krl['full_text'].apply(clean_text)\n",
        "data_mrt['clean_text'] = data_mrt['full_text'].apply(clean_text)\n",
        "data_lrt['clean_text'] = data_lrt['full_text'].apply(clean_text)\n",
        "\n",
        "# Menampilkan hasil dataset clean_text\n",
        "print(f\"DATA KRL \\n {data_krl.head()}\\n\")\n",
        "print(f\"DATA MRT \\n {data_mrt.head()}\\n\")\n",
        "print(f\"DATA LRT \\n {data_lrt.head()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BMrzq6SG6Yv",
        "outputId": "0a510bf3-fb4b-4c09-cfbb-1125d40eecde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA KRL \n",
            "                                            full_text  \\\n",
            "0  @miaetsumi Hai, Kak. Untuk kartu KRL Commuter ...   \n",
            "1  Keujanan di Bogor, menggigil selama di KRL, pa...   \n",
            "2  @tanyarlfes Karena aku bkn orang jakarta, tiap...   \n",
            "3  @adriansyahyasin Justru di hari lebaran itu KR...   \n",
            "4  @JakartaAwayDay Udah gak ada ruang lagi ah di ...   \n",
            "\n",
            "                                          clean_text  \n",
            "0   hai kak untuk kartu krl commuter line dapat d...  \n",
            "1  keujanan di bogor menggigil selama di krl pas ...  \n",
            "2   karena aku bkn orang jakarta tiap kesana seru...  \n",
            "3   justru di hari lebaran itu krl sepi karena ja...  \n",
            "4   udah gak ada ruang lagi ah di jakarta mah rib...  \n",
            "\n",
            "DATA MRT \n",
            "                                            full_text  \\\n",
            "0  Ada Perubahan Jadwal Operasional MRT Jakarta S...   \n",
            "1  @UGM_FESS 4. Lebih bagus lagi kalo bisa pelaja...   \n",
            "2  https://t.co/qCPONlISDS Bali needs airport tra...   \n",
            "3  @WatchmenID Terlalu fokus dengan perang, bom d...   \n",
            "4  siapa disini yg cita-cita nya strolling arroun...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  ada perubahan jadwal operasional mrt jakarta s...  \n",
            "1    lebih bagus lagi kalo bisa pelajari halte yg...  \n",
            "2                          bali needs airport train   \n",
            "3   terlalu fokus dengan perang bom dan aksi laga...  \n",
            "4  siapa disini yg citacita nya strolling arround...  \n",
            "\n",
            "DATA LRT \n",
            "                                            full_text  \\\n",
            "0  LRT Jabodebek siap mengatasi kemacetan. Yuk ce...   \n",
            "1  Dewi Perssik Sebut Nikita Mirzani Jualan Apem ...   \n",
            "2  Viral Rok Model Melorot, Rachel Vennya Tampil ...   \n",
            "3  Kebangun abis mimpi naik LRT jakarta nyampe di...   \n",
            "4  Saat @erickthohir mendampingi presiden Jokowi ...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  lrt jabodebek siap mengatasi kemacetan yuk cek...  \n",
            "1  dewi perssik sebut nikita mirzani jualan apem ...  \n",
            "2  viral rok model melorot rachel vennya tampil b...  \n",
            "3  kebangun abis mimpi naik lrt jakarta nyampe di...  \n",
            "4  saat mendampingi presiden jokowi dalam meresmi...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan tokenisasi\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Mendefenisikan fungsi tokenisasi\n",
        "def word_tokenize(text):\n",
        "  text = nltk.word_tokenize(text)\n",
        "  return text\n",
        "\n",
        "# Mengimplementasikan fungsi tokenisasi ke dataset\n",
        "data_krl['tokenized_text'] = data_krl['clean_text'].apply(word_tokenize)\n",
        "data_mrt['tokenized_text'] = data_mrt['clean_text'].apply(word_tokenize)\n",
        "data_lrt['tokenized_text'] = data_lrt['clean_text'].apply(word_tokenize)\n",
        "\n",
        "# Menampilkan hasil dataset tokenized_text\n",
        "print(f\"DATA KRL \\n {data_krl[['clean_text', 'tokenized_text']].head()}\\n\")\n",
        "print(f\"DATA MRT \\n {data_mrt[['clean_text', 'tokenized_text']].head()}\\n\")\n",
        "print(f\"DATA LRT \\n {data_lrt[['clean_text', 'tokenized_text']].head()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBGvzJGqHVtV",
        "outputId": "94a3a6fa-0d3c-4728-97f1-afaf0bb13d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA KRL \n",
            "                                           clean_text  \\\n",
            "0   hai kak untuk kartu krl commuter line dapat d...   \n",
            "1  keujanan di bogor menggigil selama di krl pas ...   \n",
            "2   karena aku bkn orang jakarta tiap kesana seru...   \n",
            "3   justru di hari lebaran itu krl sepi karena ja...   \n",
            "4   udah gak ada ruang lagi ah di jakarta mah rib...   \n",
            "\n",
            "                                      tokenized_text  \n",
            "0  [hai, kak, untuk, kartu, krl, commuter, line, ...  \n",
            "1  [keujanan, di, bogor, menggigil, selama, di, k...  \n",
            "2  [karena, aku, bkn, orang, jakarta, tiap, kesan...  \n",
            "3  [justru, di, hari, lebaran, itu, krl, sepi, ka...  \n",
            "4  [udah, gak, ada, ruang, lagi, ah, di, jakarta,...  \n",
            "\n",
            "DATA MRT \n",
            "                                           clean_text  \\\n",
            "0  ada perubahan jadwal operasional mrt jakarta s...   \n",
            "1    lebih bagus lagi kalo bisa pelajari halte yg...   \n",
            "2                          bali needs airport train    \n",
            "3   terlalu fokus dengan perang bom dan aksi laga...   \n",
            "4  siapa disini yg citacita nya strolling arround...   \n",
            "\n",
            "                                      tokenized_text  \n",
            "0  [ada, perubahan, jadwal, operasional, mrt, jak...  \n",
            "1  [lebih, bagus, lagi, kalo, bisa, pelajari, hal...  \n",
            "2                      [bali, needs, airport, train]  \n",
            "3  [terlalu, fokus, dengan, perang, bom, dan, aks...  \n",
            "4  [siapa, disini, yg, citacita, nya, strolling, ...  \n",
            "\n",
            "DATA LRT \n",
            "                                           clean_text  \\\n",
            "0  lrt jabodebek siap mengatasi kemacetan yuk cek...   \n",
            "1  dewi perssik sebut nikita mirzani jualan apem ...   \n",
            "2  viral rok model melorot rachel vennya tampil b...   \n",
            "3  kebangun abis mimpi naik lrt jakarta nyampe di...   \n",
            "4  saat mendampingi presiden jokowi dalam meresmi...   \n",
            "\n",
            "                                      tokenized_text  \n",
            "0  [lrt, jabodebek, siap, mengatasi, kemacetan, y...  \n",
            "1  [dewi, perssik, sebut, nikita, mirzani, jualan...  \n",
            "2  [viral, rok, model, melorot, rachel, vennya, t...  \n",
            "3  [kebangun, abis, mimpi, naik, lrt, jakarta, ny...  \n",
            "4  [saat, mendampingi, presiden, jokowi, dalam, m...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_slang = 'https://raw.githubusercontent.com/adeariniputri/text-preprocesing/master/slang.csv'\n",
        "slang = pd.read_csv(url_slang)\n",
        "kata_benar = {\n",
        "    \"keujanan\": \"kehujanan\", \"kesana\": \"ke sana\", \"anget\": \"hangat\", \"bkn\": \"bukan\", \"gitu\": \"begitu\", \"gaada\": \"tidak ada\",\n",
        "    \"bareng\": \"bersama\", \"dipotongpotong\": \"potong\", \"kayak\": \"seperti\", \"moga\": \"semoga\", \"tiap\": \"setiap\", \"pureblood\": \"darah murni\",\n",
        "    \"rmh\": \"rumah\", \"gaakan\": \"tidak akan\", \"jalanyangjauhjanganlupapulang\": \"jalan yang jauh jangan lupa pulang\",\n",
        "    \"sunscreen\": \"tabir surya\", \"perhatiin\": \"perhati\", \"saranin\": \"saran\", \"datengin\": \"datang\", \"nyari\": \"cari\", \"cobain\": \"coba\",\n",
        "    \"temanteman\": \"teman\", \"nyampe\": \"sampai\", \"balik\": \"kembali\", \"edition\": \"edisi\", \"dislike\": \"tidak suka\", \"overrated\": \"tinggi\",\n",
        "    \"still\": \"masih\", \"visit\": \"kunjung\", \"gin\": \"gini\", \"gamau\": \"tidak mau\", \"desekan\": \"desak\", \"cm\": \"cuma\", \"ojol\": \"ojek online\",\n",
        "    \"stressnya\": \"stres\", \"info\": \"informasi\", \"rb\": \"ribu\", \"rela\": \"rela\", \"beritaterkini\": \"berita terkini\", \"mutualan\": \"mutual\",\n",
        "    \"bukabukaan\": \"buka\", \"nyampe\": \"sampai\", \"ngandelin\": \"andal\", \"mesti\": \"harus\", \"deket\": \"dekat\", \"nyobain\": \"coba\", \"slain\": \"selain\",\n",
        "    \"made\": \"buatan\", \"railway\": \"rel kereta\", \"knapa\": \"kenapa\", \"covering\": \"liput\", \"expanse\": \"luas\", \"endeavors\": \"upaya\",\n",
        "    \"foster\": \"mendorong\", \"traffic\": \"lalu lintas\", \"pollution\": \"polusi\", \"transforming\": \"ubah\", \"system\": \"sistem\", \"tackle\": \"mengatasi\",\n",
        "    \"formally\": \"resmi\", \"introduced\": \"kenal\", \"greater\": \"lebih besar\", \"light\": \"ringan\", \"rail\": \"rel\", \"aimed\": \"tuju\", \"countering\": \"lawan\",\n",
        "    \"congestion\": \"macet\", \"environmental\": \"lingkungan\", \"ngelihat\": \"lihat\", \"rangkainnya\": \"rangkai\", \"berpindahpindah\": \"pindah\",\n",
        "    \"tarifintegrasi\": \"tarif integrasi\", \"gede\": \"besar\", \"kenceng\": \"kencang\", \"pekerjamigranterlindungi\": \"pekerja migran terlindungi\",\n",
        "    \"aniesberjuang\": \"Anies berjuang\", \"pakeajadulu\": \"pakai saja dulu\", \"cs\": \"customer service\"\n",
        "}\n",
        "\n",
        "slang_dict = dict(zip(slang['slang'], slang['formal']))\n",
        "slang_dict.update(kata_benar)\n",
        "\n",
        "def normalize_text(tokens):\n",
        "    normalized_tokens = [slang_dict.get(word, word) for word in tokens]\n",
        "    return normalized_tokens\n",
        "\n",
        "data_krl['normalisasi'] = data_krl['tokenized_text'].apply(lambda x: normalize_text(x))\n",
        "data_mrt['normalisasi'] = data_mrt['tokenized_text'].apply(lambda x: normalize_text(x))\n",
        "data_lrt['normalisasi'] = data_lrt['tokenized_text'].apply(lambda x: normalize_text(x))\n",
        "\n",
        "print(f\"DATA KRL \\n {data_krl.head()}\\n\")\n",
        "print(f\"DATA MRT \\n {data_mrt.head()}\\n\")\n",
        "print(f\"DATA LRT \\n {data_lrt.head()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5-oBmfBymjw",
        "outputId": "f8c7efbf-38e8-42e0-ab73-f792f8e40159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA KRL \n",
            "                                            full_text  \\\n",
            "0  @miaetsumi Hai, Kak. Untuk kartu KRL Commuter ...   \n",
            "1  Keujanan di Bogor, menggigil selama di KRL, pa...   \n",
            "2  @tanyarlfes Karena aku bkn orang jakarta, tiap...   \n",
            "3  @adriansyahyasin Justru di hari lebaran itu KR...   \n",
            "4  @JakartaAwayDay Udah gak ada ruang lagi ah di ...   \n",
            "\n",
            "                                          clean_text  \\\n",
            "0   hai kak untuk kartu krl commuter line dapat d...   \n",
            "1  keujanan di bogor menggigil selama di krl pas ...   \n",
            "2   karena aku bkn orang jakarta tiap kesana seru...   \n",
            "3   justru di hari lebaran itu krl sepi karena ja...   \n",
            "4   udah gak ada ruang lagi ah di jakarta mah rib...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  [hai, kak, untuk, kartu, krl, commuter, line, ...   \n",
            "1  [keujanan, di, bogor, menggigil, selama, di, k...   \n",
            "2  [karena, aku, bkn, orang, jakarta, tiap, kesan...   \n",
            "3  [justru, di, hari, lebaran, itu, krl, sepi, ka...   \n",
            "4  [udah, gak, ada, ruang, lagi, ah, di, jakarta,...   \n",
            "\n",
            "                                         normalisasi  \n",
            "0  [hai, kakak, untuk, kartu, krl, commuter, line...  \n",
            "1  [keujanan, di, bogor, menggigil, selama, di, k...  \n",
            "2  [karena, aku, bkn, orang, jakarta, tiap, kesan...  \n",
            "3  [justru, di, hari, lebaran, itu, krl, sepi, ka...  \n",
            "4  [sudah, tidak, ada, ruang, lagi, ah, di, jakar...  \n",
            "\n",
            "DATA MRT \n",
            "                                            full_text  \\\n",
            "0  Ada Perubahan Jadwal Operasional MRT Jakarta S...   \n",
            "1  @UGM_FESS 4. Lebih bagus lagi kalo bisa pelaja...   \n",
            "2  https://t.co/qCPONlISDS Bali needs airport tra...   \n",
            "3  @WatchmenID Terlalu fokus dengan perang, bom d...   \n",
            "4  siapa disini yg cita-cita nya strolling arroun...   \n",
            "\n",
            "                                          clean_text  \\\n",
            "0  ada perubahan jadwal operasional mrt jakarta s...   \n",
            "1    lebih bagus lagi kalo bisa pelajari halte yg...   \n",
            "2                          bali needs airport train    \n",
            "3   terlalu fokus dengan perang bom dan aksi laga...   \n",
            "4  siapa disini yg citacita nya strolling arround...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  [ada, perubahan, jadwal, operasional, mrt, jak...   \n",
            "1  [lebih, bagus, lagi, kalo, bisa, pelajari, hal...   \n",
            "2                      [bali, needs, airport, train]   \n",
            "3  [terlalu, fokus, dengan, perang, bom, dan, aks...   \n",
            "4  [siapa, disini, yg, citacita, nya, strolling, ...   \n",
            "\n",
            "                                         normalisasi  \n",
            "0  [ada, perubahan, jadwal, operasional, mrt, jak...  \n",
            "1  [lebih, bagus, lagi, kalau, bisa, pelajari, ha...  \n",
            "2                      [bali, needs, airport, train]  \n",
            "3  [terlalu, fokus, dengan, perang, bom, dan, aks...  \n",
            "4  [siapa, disini, yang, citacita, nya, strolling...  \n",
            "\n",
            "DATA LRT \n",
            "                                            full_text  \\\n",
            "0  LRT Jabodebek siap mengatasi kemacetan. Yuk ce...   \n",
            "1  Dewi Perssik Sebut Nikita Mirzani Jualan Apem ...   \n",
            "2  Viral Rok Model Melorot, Rachel Vennya Tampil ...   \n",
            "3  Kebangun abis mimpi naik LRT jakarta nyampe di...   \n",
            "4  Saat @erickthohir mendampingi presiden Jokowi ...   \n",
            "\n",
            "                                          clean_text  \\\n",
            "0  lrt jabodebek siap mengatasi kemacetan yuk cek...   \n",
            "1  dewi perssik sebut nikita mirzani jualan apem ...   \n",
            "2  viral rok model melorot rachel vennya tampil b...   \n",
            "3  kebangun abis mimpi naik lrt jakarta nyampe di...   \n",
            "4  saat mendampingi presiden jokowi dalam meresmi...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  [lrt, jabodebek, siap, mengatasi, kemacetan, y...   \n",
            "1  [dewi, perssik, sebut, nikita, mirzani, jualan...   \n",
            "2  [viral, rok, model, melorot, rachel, vennya, t...   \n",
            "3  [kebangun, abis, mimpi, naik, lrt, jakarta, ny...   \n",
            "4  [saat, mendampingi, presiden, jokowi, dalam, m...   \n",
            "\n",
            "                                         normalisasi  \n",
            "0  [lrt, jabodebek, siap, mengatasi, kemacetan, a...  \n",
            "1  [dewi, perssik, sebut, nikita, mirzani, jualan...  \n",
            "2  [viral, rok, model, melorot, rachel, vennya, t...  \n",
            "3  [kebangun, habis, mimpi, naik, lrt, jakarta, n...  \n",
            "4  [saat, mendampingi, presiden, jokowi, dalam, m...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_krl[['normalisasi', 'stopwords_removal']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "H8cNsX4K1gkT",
        "outputId": "72277c72-7ecc-407a-86c3-cd5e34aeb02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['stopwords_removal'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f1f21d9a9f6e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_krl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalisasi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stopwords_removal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5943\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['stopwords_removal'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan penghapusan stopwords\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "stopword = factory.get_stop_words()\n",
        "\n",
        "# Mendefenisikan fungsi stopwords removal\n",
        "def stopwords_removal(tokens):\n",
        "  clean_tokens = []\n",
        "  for token in tokens:\n",
        "    if token not in stopword:\n",
        "      clean_tokens.append(token)\n",
        "  return clean_tokens\n",
        "\n",
        "# Mengimplementasikan fungsi stopwords_removal ke dataset\n",
        "data_krl['stopwords_removal'] = data_krl['normalisasi'].apply(stopwords_removal)\n",
        "data_mrt['stopwords_removal'] = data_mrt['normalisasi'].apply(stopwords_removal)\n",
        "data_lrt['stopwords_removal'] = data_lrt['normalisasi'].apply(stopwords_removal)\n",
        "\n",
        "# Menampilkan hasil dataset stopwords_removal\n",
        "print(f\"DATA KRL \\n {data_krl[['normalisasi', 'stopwords_removal']].head()}\\n\")\n",
        "print(f\"DATA MRT \\n {data_mrt[['normalisasi', 'stopwords_removal']].head()}\\n\")\n",
        "print(f\"DATA LRT \\n {data_lrt[['normalisasi', 'stopwords_removal']].head()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6yP5maWHePx",
        "outputId": "609cfbcc-e334-428e-c12d-fe06b59040c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA KRL \n",
            "                                          normalisasi  \\\n",
            "0  [hai, kakak, untuk, kartu, krl, commuter, line...   \n",
            "1  [keujanan, di, bogor, menggigil, selama, di, k...   \n",
            "2  [karena, aku, bkn, orang, jakarta, tiap, kesan...   \n",
            "3  [justru, di, hari, lebaran, itu, krl, sepi, ka...   \n",
            "4  [sudah, tidak, ada, ruang, lagi, ah, di, jakar...   \n",
            "\n",
            "                                   stopwords_removal  \n",
            "0  [hai, kakak, kartu, krl, commuter, line, digun...  \n",
            "1  [keujanan, bogor, menggigil, selama, krl, pas,...  \n",
            "2  [aku, bkn, orang, jakarta, tiap, kesana, seru,...  \n",
            "3  [justru, hari, lebaran, krl, sepi, jakarta, le...  \n",
            "4  [ruang, ah, jakarta, mah, ribut, tawuran, metr...  \n",
            "\n",
            "DATA MRT \n",
            "                                          normalisasi  \\\n",
            "0  [ada, perubahan, jadwal, operasional, mrt, jak...   \n",
            "1  [lebih, bagus, lagi, kalau, bisa, pelajari, ha...   \n",
            "2                      [bali, needs, airport, train]   \n",
            "3  [terlalu, fokus, dengan, perang, bom, dan, aks...   \n",
            "4  [siapa, disini, yang, citacita, nya, strolling...   \n",
            "\n",
            "                                   stopwords_removal  \n",
            "0  [perubahan, jadwal, operasional, mrt, jakarta,...  \n",
            "1  [lebih, bagus, kalau, pelajari, halte, nyambun...  \n",
            "2                      [bali, needs, airport, train]  \n",
            "3  [terlalu, fokus, perang, bom, aksi, laga, lain...  \n",
            "4  [siapa, disini, citacita, nya, strolling, arro...  \n",
            "\n",
            "DATA LRT \n",
            "                                          normalisasi  \\\n",
            "0  [lrt, jabodebek, siap, mengatasi, kemacetan, a...   \n",
            "1  [dewi, perssik, sebut, nikita, mirzani, jualan...   \n",
            "2  [viral, rok, model, melorot, rachel, vennya, t...   \n",
            "3  [kebangun, habis, mimpi, naik, lrt, jakarta, n...   \n",
            "4  [saat, mendampingi, presiden, jokowi, dalam, m...   \n",
            "\n",
            "                                   stopwords_removal  \n",
            "0  [lrt, jabodebek, siap, mengatasi, kemacetan, a...  \n",
            "1  [dewi, perssik, sebut, nikita, mirzani, jualan...  \n",
            "2  [viral, rok, model, melorot, rachel, vennya, t...  \n",
            "3  [kebangun, habis, mimpi, naik, lrt, jakarta, n...  \n",
            "4  [mendampingi, presiden, jokowi, meresmikan, ke...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_krl.to_csv('data_krl.csv', index=False)\n",
        "data_mrt.to_csv('data_mrt.csv', index=False)\n",
        "data_lrt.to_csv('data_lrt.csv', index=False)"
      ],
      "metadata": {
        "id": "Zgy4EH0Hr8Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan stem teks\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from tqdm import tqdm\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Mendefenisikan fungsi stemmer\n",
        "def stemming_text(tokens):\n",
        "  hasil_stemming = []\n",
        "  for token in tokens :\n",
        "    stemming = stemmer.stem(token)\n",
        "    hasil_stemming.append(stemming)\n",
        "  stemm = []\n",
        "  stemm = \" \".join(hasil_stemming)\n",
        "  return stemm"
      ],
      "metadata": {
        "id": "PBtw8pPWId_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimplementasikan fungsi ke dataset KRL dan menyimpan ke direktori gdrive\n",
        "tqdm.pandas(desc=\"Progress Stemming Data KRL\")\n",
        "data_krl['stemming'] = data_krl['stopwords_removal'].progress_apply(stemming_text)\n",
        "data_krl.to_csv('/content/drive/MyDrive/Tugas Akhir/Dataset Twitter/Dataset/Data_KRL_stemming.csv', index=False)"
      ],
      "metadata": {
        "id": "y3XJLutGMrTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimplementasikan fungsi ke dataset KRL dan menyimpan ke direktori gdrive\n",
        "tqdm.pandas(desc=\"Progress Stemming Data MRT\")\n",
        "data_mrt['stemming'] = data_mrt['stopwords_removal'].progress_apply(stemming_text)\n",
        "data_mrt.to_csv('/content/drive/MyDrive/Tugas Akhir/Dataset Twitter/Dataset/Data_MRT_stemming.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4-KyEjaIY9K",
        "outputId": "e027cf8b-2a5e-4cd1-bce3-476a60082bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Stemming Data MRT: 100%|██████████| 9552/9552 [26:05<00:00,  6.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimplementasikan fungsi ke dataset KRL dan menyimpan ke direktori gdrive\n",
        "tqdm.pandas(desc=\"Progress Stemming Data LRT\")\n",
        "data_lrt['stemming'] = data_lrt['stopwords_removal'].progress_apply(stemming_text)\n",
        "data_lrt.to_csv('/content/drive/MyDrive/Tugas Akhir/Dataset Twitter/Dataset/Data_LRT_stemming.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmyxYA5XIsAE",
        "outputId": "84b66ae2-7a4b-4769-cac4-572ca95bae94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Stemming Data LRT: 100%|██████████| 2308/2308 [05:39<00:00,  6.79it/s]\n"
          ]
        }
      ]
    }
  ]
}